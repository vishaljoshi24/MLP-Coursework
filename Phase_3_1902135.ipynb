{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:55:58.928408800Z",
     "start_time": "2024-01-08T22:55:56.393999700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#First specifying the path to the CSV files containing each station's data\n",
    "trainpath = 'C:/Users/we19383/DataspellProjects/MLP_coursework/morebikes2022/Train/'\n",
    "modelpath = 'C:/Users/we19383/DataspellProjects/MLP_coursework/morebikes2022/Models/'\n",
    "testpath = 'C:/Users/we19383/DataspellProjects/MLP_coursework/morebikes2022/test.csv'\n",
    "\n",
    "phase1_files = sorted([i for i in os.listdir(trainpath) if i.endswith('deploy.csv')])\n",
    "dfs = []\n",
    "\n",
    "phase3_files = sorted([i for i in os.listdir(trainpath) if i.endswith('deploy_full.csv')])\n",
    "\n",
    "for file in phase1_files:\n",
    "    csv_filepath = os.path.join(trainpath, file)\n",
    "    df = pd.read_csv(csv_filepath)\n",
    "    dfs.append(df)\n",
    "\n",
    "train = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "phase2_files = sorted([i for i in os.listdir(modelpath) if i.endswith('.csv')])\n",
    "models = []\n",
    "\n",
    "stn_list = []\n",
    "for file in phase3_files:\n",
    "    csv_filepath = os.path.join(trainpath, file)\n",
    "    stn_df = pd.read_csv(csv_filepath)\n",
    "    stn_list.append(stn_df)\n",
    "    \n",
    "stn_dfs = pd.concat(stn_list, ignore_index=True)\n",
    "\n",
    "for file in phase2_files:\n",
    "    csv_filepath = os.path.join(modelpath, file)\n",
    "    model = pd.read_csv(csv_filepath)\n",
    "    models.append(model)\n",
    "\n",
    "all_models = pd.concat(models, ignore_index=True)\n",
    "all_models\n",
    "\n",
    "test_filepath = os.path.join(testpath)\n",
    "test = pd.read_csv(test_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tdf = pd.concat([stn_dfs, train, test])\n",
    "\n",
    "tdf = tdf.sort_values(by='station')\n",
    "tdf = tdf.drop('weekday', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:55:59.022185800Z",
     "start_time": "2024-01-08T22:55:58.928408800Z"
    }
   },
   "id": "bdf5680d9b3045d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To combine the two methods, from Phase 1 and Phase 2, it would be worth using the weights from the models trained in Phase 1, concatenated with the weights from Phase 2 for features such as 'full_profile_bikes' and 'bikes_3h_ago' to test if there's any improvement in performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "878dc726b3238efd"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "ts_cv = TimeSeriesSplit(n_splits = 10,\n",
    "                        gap = 48,\n",
    "                        max_train_size = 10000,\n",
    "                        test_size=1000\n",
    "                        )\n",
    "X_train = train.drop('weekday', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:55:59.041854700Z",
     "start_time": "2024-01-08T22:55:59.022185800Z"
    }
   },
   "id": "a8dbcfd7db795e03"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(X_train.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:55:59.092184Z",
     "start_time": "2024-01-08T22:55:59.041854700Z"
    }
   },
   "id": "bd7a46800493a2d4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    bikes_3h_ago  full_profile_bikes  station\n0       0.015953            0.013988      201\n1       0.033519            0.018670      202\n2       0.008361            0.027301      203\n3       0.016177            0.026723      204\n4       0.022605            0.022409      205\n..           ...                 ...      ...\n70      0.017239            0.032161      271\n71      0.052242            0.006572      272\n72      0.054920            0.004055      273\n73      0.052284            0.009469      274\n74      0.046208            0.012073      275\n\n[75 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bikes_3h_ago</th>\n      <th>full_profile_bikes</th>\n      <th>station</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015953</td>\n      <td>0.013988</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.033519</td>\n      <td>0.018670</td>\n      <td>202</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.008361</td>\n      <td>0.027301</td>\n      <td>203</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016177</td>\n      <td>0.026723</td>\n      <td>204</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.022605</td>\n      <td>0.022409</td>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.017239</td>\n      <td>0.032161</td>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.052242</td>\n      <td>0.006572</td>\n      <td>272</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>0.054920</td>\n      <td>0.004055</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0.052284</td>\n      <td>0.009469</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0.046208</td>\n      <td>0.012073</td>\n      <td>275</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Assuming X_train and test are defined\n",
    "\n",
    "stations = X_train['station'].unique()\n",
    "weights_dfs = []\n",
    "\n",
    "for station in stations:\n",
    "    # Data for the current station\n",
    "    station_data = X_train[X_train['station'] == station]\n",
    "\n",
    "    # Extract feature and target variable\n",
    "    X_tr = station_data[['bikes_3h_ago', 'full_profile_bikes']]\n",
    "    y_tr = station_data['bikes'] / station_data['bikes'].max()\n",
    "\n",
    "    \n",
    "    X_te = test[test['station'] == station][['station', 'full_profile_bikes']]\n",
    "    y_te = test[test['station'] == station]['bikes_3h_ago'] / test['bikes_3h_ago'].max()\n",
    "\n",
    "    # Created and fit a model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # Get the coefficients (weights) and intercept\n",
    "    coefficients = model.coef_\n",
    "    intercept = model.intercept_\n",
    "\n",
    "    \n",
    "    weights_df_1 = pd.DataFrame(columns=['Feature', 'Coefficient'])\n",
    "\n",
    "    for feature, coef in zip(X_tr.columns, coefficients):\n",
    "        weights_df_1.loc[len(weights_df_1)] = [feature, coef]\n",
    "\n",
    "    # Add a row for the intercept\n",
    "    #weights_df_1.loc[len(weights_df_1)] = ['Intercept', intercept]\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    weights_dfs.append(weights_df_1)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "final_weights_df = pd.concat(weights_dfs, ignore_index=True)\n",
    "\n",
    "final_weights_df = final_weights_df.pivot(columns='Feature', values='Coefficient')\n",
    "\n",
    "# Reshape the DataFrame\n",
    "final_weights_df = pd.concat([final_weights_df['bikes_3h_ago'].dropna().reset_index(drop=True),\n",
    "                         final_weights_df['full_profile_bikes'].dropna().reset_index(drop=True)],\n",
    "                        axis=1)\n",
    "# Display the final DataFrame with weights\n",
    "final_weights_df['station'] = range(201,276)\n",
    "\n",
    "final_weights_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:55:59.512748900Z",
     "start_time": "2024-01-08T22:55:59.092184Z"
    }
   },
   "id": "c79411bbed73804c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "     station  bikes_3h_ago  full_profile_bikes\n0          1      0.518931        3.438250e-01\n1          2      0.626153        2.959324e-01\n2          3      0.595897        2.415987e-01\n3          4      0.587546        3.286884e-01\n4          5      0.331868        6.738652e-01\n..       ...           ...                 ...\n195      196      0.999998        9.656896e-07\n196      197      0.894453        2.638717e-02\n197      198      0.903765        6.661564e-02\n198      199      0.902956        3.322967e-04\n199      200      0.937638        1.853516e-02\n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station</th>\n      <th>bikes_3h_ago</th>\n      <th>full_profile_bikes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.518931</td>\n      <td>3.438250e-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.626153</td>\n      <td>2.959324e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.595897</td>\n      <td>2.415987e-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.587546</td>\n      <td>3.286884e-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.331868</td>\n      <td>6.738652e-01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>196</td>\n      <td>0.999998</td>\n      <td>9.656896e-07</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>197</td>\n      <td>0.894453</td>\n      <td>2.638717e-02</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>198</td>\n      <td>0.903765</td>\n      <td>6.661564e-02</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>199</td>\n      <td>0.902956</td>\n      <td>3.322967e-04</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>200</td>\n      <td>0.937638</td>\n      <td>1.853516e-02</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path = 'C:/Users/we19383/DataspellProjects/MLP_coursework/morebikes2022/Models/'\n",
    "train_data = os.path.join(train_file_path)\n",
    "model_type = ['full', 'full_temp']\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# Iterate through each station\n",
    "for i in range(1, 201):\n",
    "    # Create an empty DataFrame to store the weights for the current station\n",
    "    station_dict = {'station': i}\n",
    "\n",
    "    # Iterate through each model for the current station\n",
    "    for j in range(len(model_type)):  # Assuming models are named model1.csv, model2.csv, ..., model6.csv\n",
    "        model_filename = os.path.join(train_file_path, f\"model_station_{i}_rlm_{model_type[j]}.csv\")\n",
    "        #print(model_filename)\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(model_filename):\n",
    "            # Load the model weights into a DataFrame\n",
    "            model_weights = pd.read_csv(model_filename)\n",
    "            #print(model_weights)\n",
    "\n",
    "            bikes_3h_ago = model_weights['weight'][1]\n",
    "            full_profile_bikes = model_weights['weight'][2]\n",
    "\n",
    "            avg_bikes_3h_ago = np.mean(bikes_3h_ago)\n",
    "            avg_full_profile_bikes = np.mean(full_profile_bikes)\n",
    "\n",
    "            station_dict[f\"bikes_3h_ago\"] = avg_bikes_3h_ago\n",
    "            station_dict[f\"full_profile_bikes\"] = avg_full_profile_bikes\n",
    "         \n",
    "    result_list.append(station_dict)\n",
    "\n",
    "weight_df = pd.DataFrame(result_list)\n",
    "\n",
    "\n",
    "weight_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:56:00.292227600Z",
     "start_time": "2024-01-08T22:55:59.512748900Z"
    }
   },
   "id": "50f3ead19d850c78"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     station  bikes_3h_ago  full_profile_bikes\n",
      "0          1      0.518931            0.343825\n",
      "1          2      0.626153            0.295932\n",
      "2          3      0.595897            0.241599\n",
      "3          4      0.587546            0.328688\n",
      "4          5      0.331868            0.673865\n",
      "..       ...           ...                 ...\n",
      "270      271      0.017239            0.032161\n",
      "271      272      0.052242            0.006572\n",
      "272      273      0.054920            0.004055\n",
      "273      274      0.052284            0.009469\n",
      "274      275      0.046208            0.012073\n",
      "\n",
      "[275 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate DataFrames along rows\n",
    "concatenated_df = pd.concat([weight_df, final_weights_df], ignore_index=True)\n",
    "print(concatenated_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:56:00.308123500Z",
     "start_time": "2024-01-08T22:56:00.292227600Z"
    }
   },
   "id": "8c68909af6e34fd7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MAE across all stations between 201-275 for LinearRegression(): 0.061+/- 0.000\n",
      "\n",
      "\n",
      "Average RMSE across all stations between 201-275 for LinearRegression(): 0.004+/- 0.000\n",
      "\n",
      "Average MAE across all stations between 201-275 for BayesianRidge(): 0.061+/- 0.000\n",
      "\n",
      "\n",
      "Average RMSE across all stations between 201-275 for BayesianRidge(): 0.004+/- 0.000\n",
      "\n",
      "Average MAE across all stations between 201-275 for HistGradientBoostingRegressor(): 0.092+/- 0.000\n",
      "\n",
      "\n",
      "Average RMSE across all stations between 201-275 for HistGradientBoostingRegressor(): 0.008+/- 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "bayes_rid = BayesianRidge()\n",
    "hgb = HistGradientBoostingRegressor()\n",
    "\n",
    "def station_models_v3(model):\n",
    "    \"\"\"This function will iterate over each unique station ID and apply a selected model to each station. It will then store the MAE and RMSE for each station, in a dictionary.\"\"\"\n",
    "\n",
    "\n",
    "    station_models = {} #this dictionary will store individual models for each station\n",
    "    station_maes = []\n",
    "    station_rmses = []\n",
    "    # Extract training data for stations 1-200\n",
    "    train_df = concatenated_df[concatenated_df['station'] <= 200]\n",
    "    X_train = train_df[['station', 'full_profile_bikes']]\n",
    "    y_train = train_df['bikes_3h_ago']/train_df['bikes_3h_ago'].max()\n",
    "\n",
    "    # Train the model on stations 1-200\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    for station in range(201, 276):\n",
    "        # Extract test data for the current station\n",
    "        test_data_station = concatenated_df[concatenated_df['station'] == station]\n",
    "\n",
    "\n",
    "        X_test = test_data_station[['station', 'full_profile_bikes']]\n",
    "        y_test = test_data_station['bikes_3h_ago'] / test_data_station['bikes_3h_ago'].max()\n",
    "\n",
    "        # Make predictions on the test data for the current station\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        rmse = (mean_squared_error(y_test, predictions))\n",
    "        station_maes.append(mae)\n",
    "        station_rmses.append(rmse)\n",
    "        #print(f\"This is the mean absolute error for station {station}: {mae:.3f}\")\n",
    "\n",
    "    # Calculate and print the average MAE\n",
    "    average_mae = np.mean(station_maes)\n",
    "    average_rmse = np.mean(station_rmses)\n",
    "    print(f\"\\nAverage MAE across all stations between 201-275 for {model}: {average_mae:.3f}+/- {average_mae.std():.3f}\\n\")\n",
    "    print(f\"\\nAverage RMSE across all stations between 201-275 for {model}: {average_rmse:.3f}+/- {average_rmse.std():.3f}\\n\")\n",
    "\n",
    "station_models_v3(lin_reg)\n",
    "station_models_v3(bayes_rid)\n",
    "station_models_v3(hgb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:56:02.508720100Z",
     "start_time": "2024-01-08T22:56:00.308123500Z"
    }
   },
   "id": "e8c9c31cf7f7f4e7"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for LinearRegression():     0.051 +/- 0.008\n",
      "Root Mean Squared Error for LinearRegression(): 0.068 +/- 0.013\n",
      "Mean Absolute Error for BayesianRidge():     0.050 +/- 0.008\n",
      "Root Mean Squared Error for BayesianRidge(): 0.067 +/- 0.013\n",
      "Mean Absolute Error for HistGradientBoostingRegressor():     0.046 +/- 0.009\n",
      "Root Mean Squared Error for HistGradientBoostingRegressor(): 0.064 +/- 0.016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "tdf = tdf.fillna(tdf.mean())\n",
    "X = tdf.drop('bikes', axis=1)\n",
    "y = tdf['bikes']/tdf['bikes'].max()\n",
    "\n",
    "def all_stations_v3(model, X, y, cv):\n",
    "    \"\"\"This function evaluates the mean absolute error and root-mean-square error for the bik rental data set, based on the cross validation split and model given\"\"\"\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"],\n",
    "    )\n",
    "    mae = -cv_results[\"test_neg_mean_absolute_error\"]\n",
    "    rmse = -cv_results[\"test_neg_root_mean_squared_error\"]\n",
    "    print(\n",
    "        f\"Mean Absolute Error for {model}:     {mae.mean():.3f} +/- {mae.std():.3f}\\n\"\n",
    "        f\"Root Mean Squared Error for {model}: {rmse.mean():.3f} +/- {rmse.std():.3f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "all_stations_v3(lin_reg,X, y, cv=ts_cv)\n",
    "all_stations_v3(bayes_rid,X, y, cv=ts_cv)\n",
    "all_stations_v3(hgb, X, y, cv=ts_cv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:56:26.100906100Z",
     "start_time": "2024-01-08T22:56:02.508720100Z"
    }
   },
   "id": "2fc4825033e295d0"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MAE across all stations between 201-275 for LinearRegression(): 0.214+/- 0.000\n",
      "\n",
      "\n",
      "Average RMSE across all stations between 201-275 for LinearRegression(): 0.241+/- 0.000\n",
      "\n",
      "Average MAE across all stations between 201-275 for BayesianRidge(): 0.215+/- 0.000\n",
      "\n",
      "\n",
      "Average RMSE across all stations between 201-275 for BayesianRidge(): 0.241+/- 0.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ts_cv = TimeSeriesSplit(n_splits = 3,\n",
    "                        gap = 48,\n",
    "                        max_train_size = 10000,\n",
    "                        test_size=10\n",
    "                        )\n",
    "\n",
    "def station_models_v4(model):\n",
    "    \"\"\"This function will iterate over each unique station ID and apply a selected model to each station. It will then store the MAE and RMSE for each station, in a dictionary.\"\"\"\n",
    "\n",
    "    station_models = {} #this dictionary will store individual models for each station\n",
    "\n",
    "    station_maes = []\n",
    "    station_rmses = []\n",
    "\n",
    "    stations = tdf['station']\n",
    "    for station in test['station'].unique():\n",
    "        #data for the current station\n",
    "        station_data = tdf[tdf['station'] == station]\n",
    "\n",
    "\n",
    "        #Extract feature and target variable\n",
    "        feat = station_data[['full_profile_bikes', 'latitude']]\n",
    "        targ = station_data['bikes_3h_ago']/station_data['bikes_3h_ago'].max()\n",
    "\n",
    "        cv_scores = cross_validate(model, feat, targ, cv=ts_cv, scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"])\n",
    "\n",
    "        # Convert scores to positive values and calculate the mean\n",
    "        mae = -cv_scores[\"test_neg_mean_absolute_error\"]\n",
    "        rmse = -cv_scores[\"test_neg_root_mean_squared_error\"]\n",
    "\n",
    "        # print(\n",
    "        #     f\"Average Mean Absolute Error for station {station}:     {mae.mean():.3f} +/- {mae.std():.3f}\\n\"\n",
    "        #     f\"Average Root Mean Squared Error for station {station}: {rmse.mean():.3f} +/- {rmse.std():.3f}\"\n",
    "        # )\n",
    "        station_maes.append(mae)\n",
    "        station_rmses.append(rmse)\n",
    "    # Calculate and print the average MAE\n",
    "    average_mae = np.mean(station_maes)\n",
    "    average_rmse = np.mean(station_rmses)\n",
    "    print(f\"\\nAverage MAE across all stations between 201-275 for {model}: {average_mae:.3f}+/- {average_mae.std():.3f}\\n\")\n",
    "    print(f\"\\nAverage RMSE across all stations between 201-275 for {model}: {average_rmse:.3f}+/- {average_rmse.std():.3f}\\n\")\n",
    "\n",
    "station_models_v4(lin_reg)\n",
    "station_models_v4(bayes_rid)\n",
    "#station_models_v4(hgb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T23:04:19.501522800Z",
     "start_time": "2024-01-08T23:04:16.909616Z"
    }
   },
   "id": "2341db82782476cb"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T22:59:06.804443500Z",
     "start_time": "2024-01-08T22:59:06.776858300Z"
    }
   },
   "id": "4c9c611401b37088"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
